{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Sheet 9\n",
    "\n",
    "- To be completed by **9am** on **MONDAY 29th Apr** and uploaded to [Problem Sheet 9 submission point](https://moodle.bath.ac.uk/mod/assign/view.php?id=1327082) on Moodle.\n",
    "\n",
    "## Perceptron algorithm and Hessian for the Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (a):\n",
    "Consider the dataset $\\mathbf{D} = \\{(\\mathbf{x}_1,y_1), (\\mathbf{x}_2,y_2)\\}$ from Problem Sheet 6, where\n",
    "$$\n",
    "\\mathbf{x}_1 = \\begin{bmatrix}-1 \\\\ 1\\end{bmatrix}, \\qquad \\mathbf{x}_2 = \\begin{bmatrix}2 \\\\ -1\\end{bmatrix},\n",
    "$$\n",
    "and $y_1=1$, $y_2=-1$.\n",
    "\n",
    "- Calculate iterations $\\boldsymbol\\theta_0\\ldots,\\boldsymbol\\theta_k$ of the Perceptron algorithm until convergence ($y_i \\langle \\boldsymbol\\theta_k, \\mathbf{x}_i\\rangle >0$ for both $i=1$ and $2$) for two choices of $i_0$ in the first step:\n",
    "  - when $i_0=1$ is selected;\n",
    "  - when $i_0=2$ is selected.\n",
    "- Which of these two scenarios produces $\\boldsymbol\\theta_k$ collinear to the Support Vector Machine solution $\\boldsymbol\\theta^* = (-1/2,1/2)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b) (Warm-up):\n",
    "\n",
    "- Suggest a method to choose $i_k$ that gives the fastest estimated convergence of the Perceptron algorithm, that is, the largest practically computable lower bound of $\\cos \\angle (\\boldsymbol\\theta^*,\\boldsymbol\\theta_{k+1})$ in Theorem 4.38."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c) (Warm-up):\n",
    "Let $T = T^\\top \\in \\mathbb{R}^{n \\times n}$ be a symmetric matrix with positive eigenvalues, and let\n",
    "$$\n",
    "H = \\begin{bmatrix}d_1 & \\\\ & d_2 \\\\ & & \\ddots \\\\ & & & d_n\\end{bmatrix} + T\n",
    "$$\n",
    "with $d_k\\ge 0$, $k=1,\\ldots,n$. \n",
    "\n",
    "- Prove that $H$ is invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (d):\n",
    "\n",
    "Consider $\\boldsymbol\\theta \\in \\mathbb{R}^n$ and a function $L(\\boldsymbol\\theta) = \\sum_{k=1}^n \\theta_k^4 + \\theta_1^2 + \\sum_{k=2}^n (\\theta_k - \\theta_{k-1})^2 + \\theta_n^2$.\n",
    "\n",
    "- Find the Hessian $\\nabla^2 L(\\boldsymbol\\theta)$.\n",
    "- Prove that $\\nabla^2 L(\\boldsymbol\\theta)$ is invertible for any $\\boldsymbol\\theta\\in\\mathbb{R}^n$. _Hint: Use Task (c) and Example 5.7 from Numerical Analysis:_\n",
    "\n",
    "$$\n",
    "T = \\begin{bmatrix}2 & -1 \\\\ -1 & 2 & -1 \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & & \\end{bmatrix} \\quad \\Rightarrow \\quad \\lambda_k(T) = 2\\left(1-\\cos\\left(\\frac{k\\pi}{n+1}\\right)\\right), \\quad k=1,\\ldots,n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "- Write a Python function `PerceptronM(X,y, K=100)` for the modified Perceptron algorithm designed in Task (b), with the same inputs `X`, `y` and `K` as in the original `Perceptron` function in the `Perceptron.ipynb` notebook. You can also test your function on the same example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
