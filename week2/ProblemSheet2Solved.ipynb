{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Sheet 2\n",
    "\n",
    "- To be completed by **4pm** on Fri **16th Feb** and uploaded to [Problem Sheet 2 submission point](https://moodle.bath.ac.uk/mod/assign/view.php?id=1195365) on Moodle.\n",
    "\n",
    "In Tasks (a)-(c), consider a simplified case of $n=1$ and $h_{\\theta}(x) = \\theta x$. Assume quadratic pointwise loss, $\\ell(y,\\hat y) = (y-\\hat y)^2.$\n",
    "Assume that data are samples of a random variable pair $(X,Y) \\sim \\mathbb{P}$.\n",
    "\n",
    "## Task (a) (Warm-up)\n",
    "\n",
    "- Find the expected risk $\\mathbb{E}[\\ell(h_{\\theta}(X),Y)]$ in terms of $\\theta$ and suitable expectations.\n",
    "- Find the best parameter $\\theta^{best} = \\arg\\min_{\\theta \\in \\mathbb{R}} \\mathbb{E}[\\ell(h_{\\theta}(X),Y)].$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "$$\n",
    "\\mathbb{E}[\\ell(h_{\\theta}(X),Y)] = \\mathbb{E}[(\\theta X - Y)^2] = \\mathbb{E}[\\theta^2 X^2 - 2 \\theta X Y + Y^2] = \\theta^2 \\mathbb{E}[X^2] - 2 \\theta \\mathbb{E}[XY] + \\mathbb{E}[Y^2].\n",
    "$$\n",
    "Note that $\\theta$ is independent of $X$ and $Y$, hence it can be taken out of the expectation. In contrast, $X$ and $Y$ are dependent, so the product $XY$ should remain under the expectation.\n",
    "\n",
    "Differentiating this over $\\theta$ and taking the derivative to zero gives\n",
    "$$\n",
    "\\frac{d \\mathbb{E}[\\ell(h_{\\theta}(X),Y)]}{d\\theta}(\\theta^{best}) = 2 \\theta^{best} \\mathbb{E}[X^2] - 2 \\theta^{best} \\mathbb{E}[XY] = 0\n",
    "$$\n",
    "which gives\n",
    "$$\n",
    "\\theta^{best} = \\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^2]}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b)\n",
    "- Assume $X$ is uniformly distributed on $[-1,1]$, $X \\sim \\mathcal{U}(-1,1)$, and consider two options of generating data:\n",
    "  - $Y = X$, and \n",
    "  - $Y = X - X^3$.\n",
    "  \n",
    "For each of those options for $Y$, compute $\\theta^{best}$ and the corresponding expected risk $\\mathbb{E}[\\ell(h_{\\theta^{best}}(X),Y)]$. What can you say about these $\\theta^{best}$ and the accuracy of the prediction rule $h_{\\theta^{best}}$ in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "Using the formula from Task (a), \n",
    "$$\n",
    "\\theta^{best} = \\frac{\\int_{-1}^1 x^2 \\frac{1}{2} dx}{\\int_{-1}^{1}x^2 \\frac{1}{2} dx} = 1, \n",
    "\\quad \\text{and} \\quad \n",
    "\\theta^{best} = \\frac{\\int_{-1}^1 (x^2 - x^4) \\frac{1}{2} dx}{\\int_{-1}^{1}x^2 \\frac{1}{2} dx} = 1 - \\frac{2/5}{2/3} = \\frac{2}{5}\n",
    "$$\n",
    "for $Y=X$ and $Y=X-X^3$, respectively. The expected risk is trivially $0$ in the first case, and \n",
    "$$\n",
    "\\mathbb{E}[\\ell(h_{\\theta^{best}}(X),Y)] = \\underbrace{\\frac{1}{2}}_{f_X}\\left(\\frac{4}{25} \\frac{2}{3} - 2 \\frac{2}{5} \\left(\\frac{2}{3} - \\frac{2}{5}\\right) + \\left(\\frac{2}{3} - 2 \\frac{2}{5} + \\frac{2}{7}\\right)\\right) = \\frac{12}{525}\n",
    "$$\n",
    "in the second case. Note that $Y=X$ can be resolved by the prediction rule $h_{\\theta}(x) = \\theta x$ exactly with $\\theta=1=\\theta^{best}$, while in the second case $X^3$ cannot be resolved by a linear function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c) \n",
    "Assume $X \\sim \\mathcal{U}(-1,1)$ as before, but the data $Y = X + \\Xi$ is **noisy**, that is, a function of $X$ perturbed by another random variable $\\Xi$ which is **independent of** $X$. Assume $\\mathbb{E}[\\Xi] = 0$ and $\\mathrm{Var}[\\Xi] < \\infty$, where $\\mathrm{Var}[\\Xi]$ is the variance.\n",
    "- Find $\\theta^{best} = \\arg\\min_{\\theta \\in \\mathbb{R}} \\mathbb{E}[\\ell(h_{\\theta}(X),Y)]$ under these new assumptions. Compare it with $\\theta^{best}$ from Task (b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "Similarly to Task (a),\n",
    "$$\n",
    "\\mathbb{E}[\\ell(h_{\\theta}(X),Y)] = \\mathbb{E}[(\\theta X - Y)^2] = \\mathbb{E}[\\theta^2 X^2 - 2 \\theta X (X+\\Xi) + X^2 + 2X \\Xi + \\Xi^2],\n",
    "$$\n",
    "but now remember that (i) $\\mathbb{E}[X\\Xi] = \\mathbb{E}[X] \\mathbb{E}[\\Xi]$ due to independence, and (ii) $\\mathbb{E}[\\Xi]=0$ by assumption. So the terms depending linearly on $\\Xi$ vanish, and we obtain\n",
    "$$\n",
    "\\mathbb{E}[\\ell(h_{\\theta}(X),Y)] = \\theta^2 \\mathbb{E}[X^2] - 2 \\theta \\mathbb{E}[X^2] + \\mathbb{E}[X^2] + \\mathrm{Var}[\\Xi],\n",
    "$$\n",
    "where for the last term we used that $\\mathbb{E}[\\Xi^2] = \\mathrm{Var}[\\Xi]$ if $\\mathbb{E}[\\Xi]=0$. Since this term is finite, so is the expected risk for finite $\\theta$, so we can differentiate it and find again that $\\theta^{best} = 1$. \n",
    "\n",
    "We see that a zero-mean noise has no effect on the best prediction rule! This underpins the success of supervised learning with big data, $|D| \\gg 1$,\n",
    "when the empirical risk is almost the same as the expected risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: simulating the \"true\" distribution\n",
    "\n",
    "For testing the convergence of the empirical risk we cannot use the temperature data (or any actual data in fact), since it's obviously finite, and we cannot let $|D| \\rightarrow \\infty$. To select a _class_ of models, or to test numerical algorithms, one often designs a **synthetic** distribution with known properties. One can then sample as many realisations from this distribution as desired.\n",
    "\n",
    "- **Write** a Python **function** `TrueSample()` which returns a pair x,y which is a random sample from the following distribution:\n",
    "   - $X \\sim \\mathcal{U}(-1,1)$ is a random value uniformly distributed between -1 and 1;\n",
    "   - for a given $X$, compute the label as $Y = X - X^3 + \\frac{1}{10} \\Xi$, where $\\Xi \\sim \\mathcal{N}(0,1)$ is a random variable with the standard normal distribution.   \n",
    "   \n",
    "   _Hint: read upon [numpy.random](https://numpy.org/doc/1.16/reference/routines.random.html) module_\n",
    " \n",
    "- **Compute** 30 samples of x and y from `TrueSample()` and store them in _numpy_ arrays X and Y, respectively.\n",
    "- **Plot** array Y vs array X using `plot()` from _matplotlib_'s _pyplot_ module. Make sure you plot **only points** (x,y) (not lines connecting them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt    \n",
    "\n",
    "def TrueSample():\n",
    "    x = np.random.uniform(-1,1)\n",
    "    y = x - x**3 + 0.1*np.random.randn()\n",
    "    return x,y\n",
    "\n",
    "Nsamples = 30\n",
    "Y = np.zeros(Nsamples)\n",
    "X = np.zeros(Nsamples)\n",
    "for i in range(Y.size):\n",
    "    X[i],Y[i] = TrueSample()\n",
    "\n",
    "plt.plot(X,Y, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: convergence of the parameter\n",
    "- **Copy** over functions `features` and `optimise_loss` from Problem Sheet 1 (your implementation or my model solution)\n",
    "- Take $n=1$ and **compute** $\\boldsymbol\\theta^* \\in \\mathbb{R}^2$ using `optimise_loss` applied to the data X and Y prepared in Task 1.\n",
    "- **Vary** the number of samples in Task 1 in a range 30, 100, 300, 1000, 3000, and for each corresponding realisation of X and Y compute the corresponding $\\boldsymbol\\theta^*$.\n",
    "- **Compare** $\\theta^*_1$ with $\\theta^{best}$ found in Task (b) as the number of samples increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00354743  0.44412374]\n"
     ]
    }
   ],
   "source": [
    "def features(x,n):\n",
    "    powers = np.arange(n+1)               # [0,1,2,...,n]\n",
    "    powers = np.reshape(powers, (1, -1))  # Make it explicitly a row vector\n",
    "    x = np.reshape(x, (-1, 1))            # Make it explicitly a column vector\n",
    "    return x**powers                      # Python automatically broadcasts the vectors to each others' shapes \n",
    "                                          # and takes the power between the resulting matrices elementwise\n",
    "\n",
    "def optimise_loss(V,y):\n",
    "    return np.linalg.solve(V.T @ V, V.T @ y)\n",
    "\n",
    "theta = optimise_loss(features(X,1),Y)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (Warm-up): data splitting\n",
    "\n",
    "- **Write a Python function** `split_data(X,Y,K,k)` that takes as input _numpy_ arrays X and Y as defined previously, a positive integer number of chunks K the data should be split into, and an index $0\\le$ k $<$ K. The function should split X and Y into K subsets of equal size (you can assume that K divides the size of X and Y) and **return** 4 outputs: Xtrain, Ytrain, Xtest, Ytest, where Xtest and Ytest are the $k$-th subsets of X and Y, respectively, and Xtrain and Ytrain contain the rest of X and Y, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X,Y,K,k):\n",
    "    # Create an index array, split that, and then take X and Y at this index array\n",
    "    N = X.shape[0]\n",
    "    test_range = range(k*N//K, (k+1)*N//K)  # index array of the test range\n",
    "    Xtest = X[test_range]\n",
    "    Xtrain = np.delete(X, test_range)  # delete Xtest from X\n",
    "    Ytest = Y[test_range]\n",
    "    Ytrain = np.delete(Y, test_range)  # delete Xtest from X\n",
    "    return Xtrain, Ytrain, Xtest, Ytest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
